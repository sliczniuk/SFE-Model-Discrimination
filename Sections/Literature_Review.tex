\documentclass[../Article_Sensitivity_Analsysis.tex]{subfiles}
\graphicspath{{\subfix{../Figures/}}}
\begin{document}
	
	In the study of dynamical systems, selecting the most accurate model to represent a physical process is crucial for effective prediction, control, and understanding of underlying mechanisms. When multiple models are trained on the same dataset but exhibit subtle structural differences, their responses may diverge in nuanced ways. Traditional model selection criteria often fail to capture these subtleties, making it necessary to employ a robust statistical framework for optimal model discrimination.
	
	The process of discriminating between competing models typically follows a sequential approach, involving two iterative steps. The first is the design phase, where a discrimination criterion is used to select the next experiment. This criterion, which reflects the information content of potential experimental conditions, helps identify the experiment that is expected to provide the most information for distinguishing between models. Once the experiment is conducted, the second step—data analysis—is performed. A stopping rule is then applied to determine if one model can be deemed significantly better than the others. If no clear distinction is made, the process is repeated. Most model discrimination criteria rely on either maximum divergence or maximum entropy principles.
	
	Building on information theory and a Bayesian approach, \citet{Box1967} introduced a sequential design procedure for model discrimination. Since entropy measures the amount of available information about a system, additional experiments should be selected to maximize the expected change in entropy, thereby increasing the information obtained about the system through successive experiments.
	
	\citet{BuzziFerraris1983} observed that the performance of Box’s sequential design for model discrimination depends on the order in which experimental observations are processed. This is due to the recursive nature of updating model probabilities. As model probabilities should be independent of the data presentation order, the authors noted that experiments should be selected in regions where differences in prediction variances are large, rather than where differences in model responses are most pronounced. They applied this approach to two cases: ammonia synthesis from nitrogen and hydrogen, and vapor-phase chlorination of tetrachloroethane using activated silica gel at 200 $^\circ C$.
	
	\citet{Chen2003} proposed a novel method for designing optimally informative dynamic experiments aimed at discriminating among several competing multiresponse nonlinear dynamic models, which are generally described by systems of differential and algebraic equations. Their approach extends \citet{BuzziFerraris1983}' discrimination criterion to dynamic systems, reformulating the experimental design problem as an optimal control problem. This method was applied to the fed-batch fermentation of Baker's yeast, with the goal of discriminating between four competing models by identifying optimal profiles for the dilution factor and inlet substrate concentration.
	
\end{document}